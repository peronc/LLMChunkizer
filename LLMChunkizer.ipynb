{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Large Language Model Chunkizer\n",
    "##Introduction\n",
    "In this notebook, I demonstrate how __LLMChunkizerLib__ leverages a Large Language Model (LLM) to split text (even from large documents) into coherent chunks that preserve the same concept or idea."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Import Library\n",
    "This notebook leverages LangChain and the OpenAI model deployed on Azure.\n",
    "\n",
    "First, we import the necessary standard libraries, including os, langchain, and dotenv.\n",
    "\n",
    "Next, we import my llm_chunkizer class, which provides several static methods essential for split document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain_openai.chat_models.azure import AzureChatOpenAI\n",
    "from dotenv import load_dotenv\n",
    "from LLMChunkizerLib.chunkizer import llm_chunkizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Setting variables\n",
    "Following that, we need to import the necessary variables required for utilizing Azure OpenAI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "azure_deployment = os.getenv(\"AZURE_DEPLOYMENT\")\n",
    "temperature = float(os.getenv(\"TEMPERATURE\"))\n",
    "api_key  = os.getenv(\"AZURE_OPENAI_API_KEY\")\n",
    "endpoint = os.getenv(\"AZURE_OPENAI_ENDPOINT\")\n",
    "api_version = os.getenv(\"API_VERSION\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Define database\n",
    "In a real-world scenario, I obtain paragraphs from a 30-page Word document. However, to simplify this example, I will create a list containing three paragraphs from __Around the World in Eighty Days__."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = [ \n",
    "     \"\"\"On October 2, 1872, Phileas Fogg, an English gentleman, left London for an extraordinary journey. \n",
    "\tHe had wagered that he could circumnavigate the globe in just eighty days. \n",
    "\tFogg was a man of strict habits and a very methodical life; everything was planned down to the smallest detail, and nothing was left to chance.\n",
    "\tHe departed London on a train to Dover, then crossed the Channel by ship. His journey took him through many countries, \n",
    "\tincluding France, India, Japan, and America. At each stop, he encountered various people and faced countless adventures, but his determination never wavered.\"\"\",\n",
    "\n",
    "    \"\"\"However, time was his enemy, and any delay risked losing the bet. With the help of his faithful servant Passepartout, Fogg had to face \n",
    "\tunexpected obstacles and dangerous situations.\"\"\",\n",
    "\t\"\"\"Yet, each time, his cunning and indomitable spirit guided him to victory, while the world watched in disbelief.\"\"\",\n",
    "\n",
    "    \"\"\"With one final effort, Fogg and Passepartout reached London just in time to prove that they had completed their journey in less than eighty days. \n",
    "\tThis extraordinary adventurer not only won the bet but also discovered that the true treasure was the friendship and experiences he had accumulated along the way.\"\"\"\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Initiate LLM\n",
    "Now I create an AzureOpenAI LLM GPT-4o . "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the LLM\n",
    "llm = AzureChatOpenAI(api_key=api_key, azure_endpoint=endpoint, azure_deployment=azure_deployment, api_version=api_version,temperature=temperature)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Block creation\n",
    "Now, I need to take the paragraphs and transform them into blocks of text, each with a maximum size of 200 tokens. The block size is arbitrary, and in a real-world scenario, I typically consider block sizes ranging from 3,000 to 5,000 tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "refined_blocks = llm_chunkizer.split_document_into_blocks(documents, 200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, block in enumerate(refined_blocks):\n",
    "    if (block.strip() != ''):\n",
    "        print(f\"{idx}: {block}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Chunkize blocks\n",
    "\n",
    "In the chunk_text_with_llm function, I split the block into chunks and address the potential issue of adjacent paragraphs that convey the same idea but were initially separated into distinct blocks.\n",
    "This is important because splitting related information can lead to a loss of context and negatively affect the understanding of the content when processed by the model.\n",
    "To mitigate this, I take the last two chunks (if they exist) derived from the current block and append them to the beginning of the next block before analyzing it.\n",
    "This ensures that related concepts are kept together, preserving their context and improving the overall coherence of the information. This process is repeated for all remaining blocks.            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_chunks = llm_chunkizer.chunk_text_with_llm(llm, refined_blocks)\n",
    "for idx, chunk in enumerate(final_chunks):\n",
    "    if (chunk.strip() != ''):\n",
    "        print(f\"{idx}: {chunk}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see how the database has been split into six distinct chunks.\n",
    "\n",
    "0: On October 2, 1872, Phileas Fogg, an English gentleman, left London for an extraordinary journey. He had wagered that he could circumnavigate the globe in just eighty days. Fogg was a man of strict habits and a very methodical life; everything was planned down to the smallest detail, and nothing was left to chance. \n",
    "1:  He departed London on a train to Dover, then crossed the Channel by ship. His journey took him through many countries, including France, India, Japan, and America. At each stop, he encountered various people and faced countless adventures, but his determination never wavered. \n",
    "2: However, time was his enemy, and any delay risked losing the bet. With the help of his faithful servant Passepartout, Fogg had to face unexpected obstacles and dangerous situations. \n",
    "3: Yet, each time, his cunning and indomitable spirit guided him to victory, while the world watched in disbelief.\n",
    "4: With one final effort, Fogg and Passepartout reached London just in time to prove that they had completed their journey in less than eighty days.\n",
    "5: This extraordinary adventurer not only won the bet but also discovered that the true treasure was the friendship and experiences he had accumulated along the way."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see what happens when I split the original database into larger blocks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "refined_blocks = llm_chunkizer.split_document_into_blocks(documents, 1000)\n",
    "\n",
    "final_chunks = llm_chunkizer.chunk_text_with_llm(llm, refined_blocks)\n",
    "for idx, chunk in enumerate(final_chunks):\n",
    "    if (chunk.strip() != ''):\n",
    "        print(f\"{idx}: {chunk}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With a larger block size, the system generates 4 chunks instead of 6. This behavior is expected, as the prompt responsible for dividing the text into chunks analyzed a larger portion of text at once and was able to create fewer chunks by using more text to represent a single concept.\n",
    "\n",
    "0: On October 2, 1872, Phileas Fogg, an English gentleman, left London for an extraordinary journey. He had wagered that he could circumnavigate the globe in just eighty days. Fogg was a man of strict habits and a very methodical life; everything was planned down to the smallest detail, and nothing was left to chance. \n",
    "1: He departed London on a train to Dover, then crossed the Channel by ship. His journey took him through many countries, including France, India, Japan, and America. At each stop, he encountered various people and faced countless adventures, but his determination never wavered.\n",
    "2: However, time was his enemy, and any delay risked losing the bet. With the help of his faithful servant Passepartout, Fogg had to face unexpected obstacles and dangerous situations. Yet, each time, his cunning and indomitable spirit guided him to victory, while the world watched in disbelief.\n",
    "3: With one final effort, Fogg and Passepartout reached London just in time to prove that they had completed their journey in less than eighty days. This extraordinary adventurer not only won the bet but also discovered that the true treasure was the friendship and experiences he had accumulated along the way.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Final Thoughts\n",
    "Ultimately, it's important to perform multiple chunking attempts, varying the block size passed to the chunkizer each time. It is essential to review the results after each attempt to determine which approach best suits the desired outcome. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
